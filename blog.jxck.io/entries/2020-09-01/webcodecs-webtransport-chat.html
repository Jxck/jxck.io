<!DOCTYPE html>
<html lang=ja>
<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
  <meta charset=utf-8>
  <meta name=viewport content="width=device-width,initial-scale=1">

  <link rel=author    href=https://jxck.io/humans.txt>
  <link rel=manifest  href=/manifest.webmanifest>
  <link rel=alternate href=/feeds/atom.xml type=application/atom+xml title=blog.jxck.io>

  <link rel=canonical href="https://blog.jxck.io/entries/2020-09-01/webcodecs-webtransport-chat.html">
  <link rel=amphtml   href="https://blog.jxck.io/entries/2020-09-01/webcodecs-webtransport-chat.amp.html">
  <link rel=preload   type=font/woff2 as=font href=/assets/font/NotoSansCJKjp-Regular-Jxck-20200904.woff2 crossorigin>

  <script async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script>
  <script defer src=/assets/js/main.js></script>
  <script defer src=/assets/js/ga.js></script>
  <script defer src=/assets/js/highlight.pack.js></script>

  <link rel=icon             type =image/svg+xml sizes=any href=https://jxck.io/assets/img/jxck.svg>
  <link rel=icon             type =image/png sizes=256x256 href=https://jxck.io/assets/img/jxck.png>
  <link rel=apple-touch-icon type =image/png sizes=256x256 href=https://jxck.io/assets/img/jxck.png>

  <meta name=author              content=Jxck>
  <meta name=description         content="ブラウザの持つ Video/Audio コーデック実装へアクセスする API として WebCodecs の仕様策定と実装が進んでいる。これにより、映像や音声の変換などといったユースケースへの応用も可能だ。本来なら WebCodecs 単体の API について解説するところ...">
  <meta name=keywords            content="webcodecs,webtransport,webrtc">
  <meta name=theme-color         content=#000000>

  <meta name=twitter:card        content=summary>
  <meta name=twitter:site        content=@jxck_>
  <meta name=twitter:url         content=https://blog.jxck.io/entries/2020-09-01/webcodecs-webtransport-chat.html>
  <meta name=twitter:title       content="WebCodecs と WebTransport でビデオチャット | blog.jxck.io">
  <meta name=twitter:description content="ブラウザの持つ Video/Audio コーデック実装へアクセスする API として WebCodecs の仕様策定と実装が進んでいる。これにより、映像や音声の変換などといったユースケースへの応用も可能だ。本来なら WebCodecs 単体の API について解説するところ...">
  <meta name=twitter:image       content=https://jxck.io/assets/img/jxck.png>

  <meta property=og:type         content=article>
  <meta property=og:url          content=https://blog.jxck.io/entries/2020-09-01/webcodecs-webtransport-chat.html>
  <meta property=og:title        content="WebCodecs と WebTransport でビデオチャット | blog.jxck.io">
  <meta property=og:site_name    content=blog.jxck.io>
  <meta property=og:description  content="ブラウザの持つ Video/Audio コーデック実装へアクセスする API として WebCodecs の仕様策定と実装が進んでいる。これにより、映像や音声の変換などといったユースケースへの応用も可能だ。本来なら WebCodecs 単体の API について解説するところ...">
  <meta property=og:image        content=https://jxck.io/assets/img/jxck.png>

  <script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage":{
      "@type":"WebPage",
      "@id":"https://blog.jxck.io"
    },
    "headline": "WebCodecs と WebTransport でビデオチャット | blog.jxck.io",
    "image": [
      "https://jxck.io/assets/img/jxck.png",
      "https://logo.jxck.io/jxck.1200x1200.png"
    ],
    "datePublished": "2020-09-01T08:00:00+08:00",
    "dateModified": "2020-09-06T08:00:00+08:00",
    "author": {
      "@type": "Person",
      "name": "Jxck",
      "image": "https://jxck.io/assets/img/jxck.png"
    },
    "publisher": {
      "@type": "Organization",
      "name": "Jxck",
      "logo": {
        "@type": "ImageObject",
        "url": "https://logo.jxck.io/jxck.60x60.png",
        "height": 60,
        "width": 60
      }
    },
    "description": "ブラウザの持つ Video/Audio コーデック実装へアクセスする API として WebCodecs の仕様策定と実装が進んでいる。これにより、映像や音声の変換などといったユースケースへの応用も可能だ。本来なら WebCodecs 単体の API について解説するところ..."
  }
  </script>

  <title>WebCodecs と WebTransport でビデオチャット | blog.jxck.io</title>
  <link rel=stylesheet property=stylesheet type=text/css href=/assets/css/body.css>
</head>
<body>
  <link rel=stylesheet property=stylesheet type=text/css href=/assets/css/header.css>
  <header>
    <nav>
      <ul>
        <li><a href=https://blog.jxck.io      ><img width=30 height=30 loading=eager src=/assets/img/blog.svg   title=blog   alt="blog logo" class=logo></a>
        <li><a href=/searches                 ><img width=30 height=30 loading=eager src=/assets/img/search.svg title=search alt=search></a>
        <li><a href="https://blog.jxck.io/entries/2020-09-01/webcodecs-webtransport-chat.amp.html#development=1" aria-label="amp version">
                                               <img width=30 height=30 loading=eager src=/assets/img/amp.svg    title=amp    alt="amp version"></a>
        <li><a href=.                         ><img width=30 height=30 loading=eager src=/assets/img/up.svg     title=up     alt="move to parent directory"></a>
        <li><a href=/feeds/atom.xml           ><img width=30 height=30 loading=eager src=/assets/img/rss.svg    title=rss    alt="rss feed"></a>
        <li><a href=https://jxck.io/humans.txt><img width=30 height=30 loading=eager src=/assets/img/humans.svg title=humans alt=huamns.txt></a>
        <li><a href=https://jxck.io           ><img width=30 height=30 loading=eager src=/assets/img/jxck.svg   title=jxck   alt="jxck logo" class=logo></a>
      </ul>
    </nav>
  </header>

  <link rel=stylesheet property=stylesheet type=text/css href=/assets/css/markdown.css>
  <link rel=stylesheet property=stylesheet type=text/css href=/assets/css/main.css>
  <main>
    <link rel=stylesheet property=stylesheet type=text/css href=/assets/css/info.css>
    <dl class=info>
      <div><dt>created_at</dt><dd><time class=created_at datetime=2020-09-01>2020-09-01</time></dd></div>
      <div><dt>updated_at</dt><dd><time class=updated_at datetime=2020-09-06>2020-09-06</time></dd></div>
      <div><dt class=tags>tags</dt><dd>[<a href="/tags/webcodecs.html">webcodecs</a><i>,</i><a href="/tags/webtransport.html">webtransport</a><i>,</i><a href="/tags/webrtc.html">webrtc</a>]</dd></div>
      <div>
        <dt>toc</dt>
        <dd>
          <details class=info>
            <summary>headdings</summary>
            <ul>
              <li><a href=#intro>## Intro</a>
              <li><a href=#webrtc>## WebRTC</a>
              <li><a href=#webtransport>## WebTransport</a>
              <li><a href=#webcodecs>## WebCodecs</a>
              <li><a href=#api>### API</a>
              <li><a href=#ビデオチャット>## ビデオチャット</a>
              <li><a href=#シリアライズ>### シリアライズ</a>
              <li><a href=#転送制御>### 転送制御</a>
              <li><a href=#メディア制御>### メディア制御</a>
              <li><a href=#表示制御>### 表示制御</a>
              <li><a href=#webcodecs-と-webtransport-の繋ぎ>### WebCodecs と WebTransport の繋ぎ</a>
              <li><a href=#outro>## Outro</a>
              <li><a href=#demo>## DEMO</a>
              <li><a href=#resources>## Resources</a>
            </ul>
          </details>
        </dd>
      </div>
    </dl>

    <link rel=stylesheet property=stylesheet type=text/css href=/assets/css/article.css>
    <article>
      <h1><a href=/entries/2020-09-01/webcodecs-webtransport-chat.html>WebCodecs と WebTransport でビデオチャット</a></h1>
      <section>
        <h2 id="intro"><a href="#intro">Intro</a></h2>
        <p>ブラウザの持つ Video/Audio コーデック実装へアクセスする API として WebCodecs の仕様策定と実装が進んでいる。
        <p>これにより、映像や音声の変換などといったユースケースへの応用も可能だ。
        <p>本来なら WebCodecs 単体の API について解説するところだが、筆者がこの API を待っていた理由であるところの「WebRTC の代替」としての WebCodecs/WebTransport の応用に注目し、背景も踏まえて解説する。
      </section>
      <section>
        <h2 id="webrtc"><a href="#webrtc">WebRTC</a></h2>
        <p>WebRTC は UDP 上に DTLS で交換した鍵を用いて、 RTP を SRTP で流し、そのシグナリングに SDP を、ホーパンチに ICE(STUN/TURN) を用いることで、 P2P ビデオチャットといったユースケースを可能にした API だ。
        <p>しかし、最初から「P2P ビデオチャット」というユースケースに寄せていることもあり、従来使われていたプロトコルスタックを応用して実現しており、 P2P ならではの問題を解決するために、全体は割と複雑な構成になっていた。(真面目にフルで実装すると 3 桁近い RFC が絡んでくる)
        <p>ところが、実際 WebRTC を用いたサービスを提供する際には、 P2P でクライアント同士を会話させるなどということはあまりなく、サービス側で持ったサーバ(SFU/MCU)で、ルーティングや QoS の調整といった様々なサービスを提供することになることが多い。
        <p>また、ブラウザ API の抽象度も高く、内部で行われる動作の機微をコントロールするには、新しい API が必要になり、クロスブラウザの切り分けが難しい場合もある。
        <p>特にコーデック周りの制御も容易ではなく、実際の映像バイナリを一切触ることなく、その中身を制御するための命令を行うといった雰囲気の実装になる。
        <p>これは、チュートリアルにあるような典型的ビデオチャットを提供するだけならうまく動くが、少し特別な実装を入れたり、その UDP トランスポートを使って別のメディア(ゲームなど)を流そうとすると、途端に扱いにくい部分が目立ってくる。
        <p>もし P2P ではなく、 Server/Client 型のデプロイを前提とし、コーデックもブラウザが持っている実装を直接触るような API があり、データは生のバイナリでやり取りできれば、その方が柔軟性が高く多くのユースケースへ応用できる。そうした発想から生まれたのが WebTransport と WebCodecs だ。
        <p>そのあたりのモチベーションは以前にも書いている。
        <ul>
          <li><a href="https://blog.jxck.io/entries/2019-08-18/webtransport-and-webcodecs.html">WebTransport と WebCodecs そして Web はどこまで &ldquo;ゲーム化&rdquo; するか</a>
        </ul>
      </section>
      <section>
        <h2 id="webtransport"><a href="#webtransport">WebTransport</a></h2>
        <p>QUIC/HTTP3 の実装が進んでから、このトランスポートを WebSocket のように直接触れる API があり、任意のバイナリを送れるようにしようという発想から始まったのが WebTransport だ。
        <p>仕様上は Http3Transport と QuicTranport の両方が検討されているが、現状 Chrome は QuicTransport のみ実装を進めている。
        <ul>
          <li><a href="https://blog.jxck.io/entries/2020-06-09/quic-transport.html">QuicTransport によるアプリケーションレイヤでの QUIC 活用</a>
        </ul>
        <p>単純に Uint8Array を自由に送ることができるため、バイナリが手元にあれば送るだけだ。
        <p>ビデオチャットの場合、問題はカメラの出力をどうバイナリで取得するかだった。
      </section>
      <section>
        <h2 id="webcodecs"><a href="#webcodecs">WebCodecs</a></h2>
        <p>WebRTC の場合は、取得した MediaStream を RTCPeerConnection に addStream/addTrack すると、そのメディに合わせてシグナリングを行い、自動でエンコード/デコードし、そのバイナリを自動的に送受信してくれるという、抽象度の高い設計になっていた。
        <link rel=stylesheet property=stylesheet type=text/css href=/assets/css/pre.css>
        <pre class=js><code translate="no">// 接続されたカメラを抽象化した MediaStream を取得
const stream = await navigator.mediaDevices.getUserMedia({video:true, audio:true})

// WebRTC の通信を抽象化した RTCPeerConnection を取得
const connection = new RTCPeerConnection(config)

// 両者を繋ぐ
stream.getTracks().forEach((track) =&gt; {
  connection.addTrack(track, stream)
})</code></pre>
        <p>この流れを見てもわかるように、従来の <code translate="no">getUserMedia()</code> で取得した MediaStream は、そこから直接カメラの映像をバイナリで取得できるような作りにはなってない。
        <p><code translate="no">&lt;video&gt;</code> や RTCPeerConnection などの対応した API に繋ぐことで、あとは中で <em>やってくれる/やってしまう</em> 、ため、外からそこに手を加えることができないのだ。
        <p>もし手を加えたい場合は、一旦 Canvas に描画する、 Insertable Stream で横取りするなどのワークアラウンドが必要だった。
        <p>カメラから取得したデータを、ブラウザが内部で持っている VP8 や H.264 などのコーデック実装でエンコード/デコードを行い、その結果をバイナリで取得できれば様々なユースケースに応用できる。
        <p>これが WebCodecs のモチベーションだ。
        <section>
          <h3 id="api"><a href="#api">API</a></h3>
          <p>今回は、まずカメラから取得したビデオストリームに注目して解説する。音声や画面キャプチャもほぼ同じように可能だ。
          <p>
            <img loading=lazy src=webcodecs-webtransport-chat.svg#500x190 alt="WebCodecs と WebTransport を用いたビデオ会議の概要図" title="overview of webcodecs & webtransport video chat" width=500 height=190>
          </p>
          <p>ビデオの場合は VideoStreamTrack を取得するところから始まる。
          <pre class=js><code translate="no">const stream = await navigator.mediaDevices.getUserMedia({video:true, audio:true})
const [videoTrack] = mediaStream.getVideoTracks()</code></pre>
          <p>ここには、カメラからの生のストリームがあるようなイメージだ。そのままでは大きいため、多くの場合は圧縮を行う。その方式が VP8 や H.264 のようなコーデックになる。
          <p>VideoTrack をエンコードするには VideoEncoder を用いる。
          <p>初期化時に output コールバックを指定し、初期化後に <code translate="no">configure()</code> でエンコードの仕様を設定する。<br>

          後から動的にエンコードパラメータを変えられるようにするために、このような API になっていると思われる。<br>

          (将来 Simulcast などに対応する場合はここが拡張されるだろう)
          <pre class=js><code translate="no">// Encoder
const videoEncoder = new VideoEncoder({
  output: function(chunk) {
    console.log(chunk)
  },
  error: function() {
    console.error(arguments)
  }
})
await videoEncoder.configure({
  codec:     &#39;vp8&#39;
  width:     640
  height:    480
  framerate: 30
})</code></pre>
          <p>VideoTrackReader を用いて  MediaStream からビデオのデータを取り出す。<br>

          ここでの単位はフレームで、この VideoFrame を VideoEncoder の <code translate="no">encode()</code> に渡すとエンコードされる。
          <pre class=js><code translate="no">const videoReader = new VideoTrackReader(videoTrack)
videoReader.start((videoFrame) =&gt; {
  videoEncoder.encode(videoFrame)
})</code></pre>
          <p>結果は VideoEncoder の初期化時に指定した output コールバックに渡り、これが vp8 でエンコードした結果の ArrayBuffer だ。
          <p>デコードもほぼ同じ、まずは初期化し <code translate="no">configure()</code> を呼ぶ。<br>

          <code translate="no">encode()</code> に vp8 の chunk を渡せばデコードしたフレームが取り出せる。
          <p><code translate="no">createImageBitmap()</code> でビットマップに変換すれば Canvas に描画できる。
          <pre class=js><code translate="no">const ctx = $canvas.getContext(&#39;2d&#39;)

// Decoder
const videoDecoder = new VideoDecoder({
  output: async function(frame) {
    const imageBitmap = await frame.createImageBitmap()
    // canvas に描画
    ctx.drawImage(imageBitmap, 0, 0)
  },
  error: function() {
    console.error(arguments)
  }
})
videoDecoder.configure({ codec: &#39;vp8&#39; })


// encoder で作った vp8 の chunk
videoDecoder.decode(chunk)</code></pre>
          <p>ちなみに VideoTrackWriter は無いため、戻した結果を <code translate="no">&lt;video&gt;</code> に流すことはできない(と思われる)。
          <p>音声も基本的に WebAudio を用いるため、音声も映像も自分で表示し、コントローラも自分で作ることになるだろう。
          <p>(現状の WebRTC でもそうしていることは多いので、あまり変わらない)
        </section>
      </section>
      <section>
        <h2 id="ビデオチャット"><a href="#ビデオチャット">ビデオチャット</a></h2>
        <p>エンコードしたバイナリを送り、受け取ってデコードすれば、ビデオ会議が可能になる。
        <p>そこで WebCodecs + WebTransport を用いたビデオチャットを簡単に作ってみた。
        <p>多人数にすると少し面倒なため、自分の映像をサーバがエコーして自分で表示する作りにしてある。
        <p>
          <picture>
            <source type=image/webp srcset=webcodecs-webtransport-chat-demo.webp#1082x1038>
            <img loading=lazy src=webcodecs-webtransport-chat-demo.gif#1082x1038 alt="WebCodecs と WebTransport で作成したビデオチャットのデモ動作風景" title="webcodecs webtransport demo">
          </picture>
        </p>
        <p>デモは最後に貼るため、以下は特に WebRTC と比較しての部分について解説する。
        <section>
          <h3 id="シリアライズ"><a href="#シリアライズ">シリアライズ</a></h3>
          <p>エンコードした Chunk は以下のような形をしている。
          <pre class=js><code translate="no">interface EncodedVideoChunk {
  constructor(EncodedVideoChunkInit init);
  readonly attribute EncodedVideoChunkType type;
  readonly attribute unsigned long long timestamp;  // microseconds
  readonly attribute unsigned long long? duration;  // microseconds
  readonly attribute ArrayBuffer data;
};</code></pre>
          <p>したがって、 <code translate="no">{type, timestamp, duration, data}</code> のようなオブジェクトをシリアライズして送り、復元する必要がある。
          <p>転送は基本的に Uint8Array 単位で行うため、今回は CBOR を採用した。しかし後述のサイズの問題があるため、少し工夫している。
        </section>
        <section>
          <h3 id="転送制御"><a href="#転送制御">転送制御</a></h3>
          <p>QUIC はパケットサイズに上限があるため、 QuicTransport でも大きいバイナリが送れず、分割される。
          <ul>
            <li>IPv6 = 1280(v6 MTU) - 40 (v6 header) - 8 (udp header) = 1232byte
            <li>IPv4 = 1280(v4 MTU) - 20 (v4 header) - 8 (udp header) = 1252byt
          </ul>
          <p>なので v4 だと PMTUD でサイズを確認しない限り 1252 以上は送れない
          <ul>
            <li><a href="https://tools.ietf.org/html/draft-ietf-quic-transport-29#section-14">https://tools.ietf.org/html/draft-ietf-quic-transport-29#section-14</a>
          </ul>
          <p>すると、キーフレームは確実にフラグメントするため、全て揃うまでバッファしないと CBOR でデコードできない。
          <p>今回は、暫定的に CBOR エンコードしたバイナリの先頭に Length をつけるようにした。
          <p>Bidirectional Stream で送れば自動で分割してくれるため、最初に Length を読んでから、長さ分のパケットが揃うまでバッファに貯めている。
          <p>このあたりを上手く転送制御する上では、やはり RTP のような既存の仕組みが欲しくなる。
          <p>CBOR はストリーミングっぽい仕組みがあった気がするため、もっとうまく書けたかもしれない。
        </section>
        <section>
          <h3 id="メディア制御"><a href="#メディア制御">メディア制御</a></h3>
          <p>デフォルトでは最初に key frame を送ったら残りは delta のみがエンコードされる。
          <p>もしどこかで絵が壊れた場合は、明示的に <code translate="no">encode({keyFrame: true})</code> するとキーフレームが取得できる。
          <p>つまり、キーフレームを得るタイミングも自分で制御でき、逆を言えば今まで RTCP などでいい感じにやってくれていたことも自分でやらないといけない。
          <p>また、絵が壊れたところで Canvas がエラーを出してくれるわけではなく、帯域が狭くなったことやロスが増えたことも誰も教えてくれないため、フィードバック制御やリカバリを自分で考える必要がある。
          <p>今回はとりあえず 10 回に一回 KeyFrame を送るようにしてみた。
        </section>
        <section>
          <h3 id="表示制御"><a href="#表示制御">表示制御</a></h3>
          <p>これまでは <code translate="no">&lt;video&gt;</code> に表示するのが基本だったが、 <code translate="no">&lt;video&gt;</code> は表示をイジるのに多少の面倒臭さがあった。
          <p>一方 <code translate="no">&lt;canvas&gt;</code> は周知の通り、表示に関する操作の方法が多く知られており、フィルタ適用、物体/顔検出、合成、傾き etc 手法やライブラリも潤沢にある。
          <p>そうした目的からあえて <code translate="no">&lt;video&gt;</code> ではなく <code translate="no">&lt;canvas&gt;</code> を選ぶサービスがもあったくらいなので、このメリットはデカイだろう。
          <p>並行している SIMD+WASM は、そうした画像処理に必要な計算を高速化することが可能なため、今回は触れなかったが、今後はそちらも試しておきたい。
        </section>
        <section>
          <h3 id="webcodecs-と-webtransport-の繋ぎ"><a href="#webcodecs-と-webtransport-の繋ぎ">WebCodecs と WebTransport の繋ぎ</a></h3>
          <p>WebCodecs の出力バイナリは、従来の WebRTC でいえば RTC 内の body 部分のみにあたる。
          <p>WebTransport の転送は、 WebRTC でいうと DTLS-SRTP の部分のみだ。
          <p>WebRTC よりも軽いスタックでビデオ会議が実現可能になったが、逆を言えば前述のようなメディアの転送制御に関わる部分は別途自分で用意する必要がある。
          <p>「自分で用意する必要がある」は、ちょっと遊んでみたい素人にとっては負荷かもしれないが、 WebRTC で困っていたサービス提供者にとっては「自分で提供することができる」と取れる場合もある。
          <p>バイナリさえあればソースがカメラである必要も、出力先が Canvas である必要もないため、その間には無限のユースケースがある。
          <p>ユースケースに応じて適切な中間ロジックを選定でき、なければ自分で JS や WASM で書くこともできるという点は、自由度をかなり上げている。
          <p>単純なビデオ会議を実現する程度なら、軽量なフレームワークをサクッと作ることは可能だし、おそらくそうしたものは多く出てくるだろう。どうしても足りない部分はまた別途標準かもあるかもしれない。
          <p>それを除けば、 WebCodecs / WebTransport の 2 つさえ実装されたブラウザでは、残りを自分たちの要件に合わせて実装していけるのは、開発者としてもサービスに個性を出しやすく、実装に多様性が生まれると期待している。
        </section>
      </section>
      <section>
        <h2 id="outro"><a href="#outro">Outro</a></h2>
        <p>WebCodecs と WebTrasnport を用いて WebRTC のようなビデオ会議が、よりシンプルなスタックで可能になった。
        <p>バイナリをエンコードし、それを送る、その間に必要なロジックは、標準ではなく要件に合わせて開発者が用意するという世界観は、 Extensible Web Manifest 以来進められてきた API の低レイヤ化の流れを組んでいるといえる。
        <p>そうして、ユースケースに特化し膨らんだ WebRTC の解体は、ブラウザが内側にもつスタックを、 ArrayBuffer を取り回すという低レベル API として開発者に提供したことによって、可能性を広げたと考えられる。
        <p>本ブログでは、ビデオ会議の側面から API を比較するため、全体の一部しか触れてないが、並行して進められている SIMD+WASM は ArrayBuffer の加工に最適なため、今後はそちらも含めて色々と試しつつ、フィードバックにつなげていきたい。
      </section>
      <section>
        <h2 id="demo"><a href="#demo">DEMO</a></h2>
        <p>動作するデモを以下に用意した。
        <ul>
          <li><a href="https://labs.jxck.io/webcodecs/">https://labs.jxck.io/webcodecs/</a>
        </ul>
      </section>
      <section>
        <h2 id="resources"><a href="#resources">Resources</a></h2>
        <ul>
          <li>
            Spec
            <ul>
              <li><a href="https://wicg.github.io/web-codecs/">https://wicg.github.io/web-codecs/</a>
            </ul>
          </li>
          <li>
            Explainer
            <ul>
              <li><a href="https://github.com/WICG/web-codecs/blob/master/explainer.md">https://github.com/WICG/web-codecs/blob/master/explainer.md</a>
            </ul>
          </li>
          <li>
            Requirements Doc
            <ul>
              <li><a href="https://docs.google.com/document/d/1fw3_aMB0-q9hOMuz_lxE8kEd-Z7vjA0wtklpx77m4yw">https://docs.google.com/document/d/1fw3_aMB0-q9hOMuz_lxE8kEd-Z7vjA0wtklpx77m4yw</a>
            </ul>
          </li>
          <li>
            Mozilla Standard Position
            <ul>
              <li><a href="https://mozilla.github.io/standards-positions/#web-codecs">https://mozilla.github.io/standards-positions/#web-codecs</a>
            </ul>
          </li>
          <li>
            Webkit Position
            <ul>
              <li><a href="https://lists.webkit.org/pipermail/webkit-dev/2020-May/031191.html">https://lists.webkit.org/pipermail/webkit-dev/2020-May/031191.html</a>
            </ul>
          </li>
          <li>
            TAG Design Review
            <ul>
              <li><a href="https://github.com/w3ctag/design-reviews/issues/433">https://github.com/w3ctag/design-reviews/issues/433</a>
            </ul>
          </li>
          <li>
            Intents
            <ul>
              <li>
                Intent to Experiment: WebCodecs
                <ul>
                  <li><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/7OdxQf5HnlQ">https://groups.google.com/a/chromium.org/g/blink-dev/c/7OdxQf5HnlQ</a>
                </ul>
              </li>
              <li>
                Intent to Implement WebCodecs
                <ul>
                  <li><a href="https://groups.google.com/a/chromium.org/forum/#!topic/blink-dev/3oVuczJ5Ty4/discussion">https://groups.google.com/a/chromium.org/forum/#!topic/blink-dev/3oVuczJ5Ty4/discussion</a>
                </ul>
              </li>
              <li>
                Intent to Prototype: ImageDecoder API extension for WebCodecs
                <ul>
                  <li><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/w1F8UGwTjZo/m/CoU8WTOxAAAJ">https://groups.google.com/a/chromium.org/g/blink-dev/c/w1F8UGwTjZo/m/CoU8WTOxAAAJ</a>
                </ul>
              </li>
            </ul>
          </li>
          <li>
            Chrome Platform Status
            <ul>
              <li><a href="https://www.chromestatus.com/feature/5669293909868544">https://www.chromestatus.com/feature/5669293909868544</a>
            </ul>
          </li>
          <li>DEMO
          <li>
            Blog
            <ul>
              <li><a href="https://blog.jxck.io/entries/2020-06-09/quic-transport.html">QuicTransport によるアプリケーションレイヤでの QUIC 活用 | blog.jxck.io</a>
              <li><a href="https://blog.jxck.io/entries/2019-08-18/webtransport-and-webcodecs.html">WebTransport と WebCodecs そして Web はどこまで &ldquo;ゲーム化&rdquo; するか | blog.jxck.io</a>
            </ul>
          </li>
          <li>Presentation
          <li>
            Issues
            <ul>
              <li><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=897297">https://bugs.chromium.org/p/chromium/issues/detail?id=897297</a>
            </ul>
          </li>
          <li>Other
        </ul>
      </section>
    </article>
  </main>
  <hr>

  <link rel=stylesheet property=stylesheet type=text/css href=/assets/css/footer.css>
  <footer>
    <p class=copyright><small>Copyright &copy; 2016 <a href=/>Jxck</a>. All Rights Reserved.</small> See <small><a href=/policies/site.html>Site Policy</a> and <a href=/policies/privacy.html>Privacy Policy</a>.</small></p>
    <ins class=adsbygoogle data-ad-layout=in-article data-ad-format=fluid data-ad-client=ca-pub-2902784829138215 data-ad-slot=9735419796></ins>
  </footer>
</body>
</html>